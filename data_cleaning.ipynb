{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data sets\n",
    "\n",
    "tweets_2020 = pd.read_csv('data/needed/raw/2020.csv', index_col=0)\n",
    "tweets_2021 = pd.read_csv('data/needed/raw/2021.csv')\n",
    "tweets_2022 = pd.read_csv('data/needed/raw/2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_2022 contains duplicates with very slightly different likes, replies and retweet counts; we remove them\n",
    "tweets_2022 = tweets_2022.drop_duplicates(subset=[\"id\"], keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id_str', 'hour', 'nlikes', 'search', 'nreplies', 'nretweets', 'day'}\n",
      "{'likes_count', 'time', 'retweets_count', 'replies_count', 'mentions'}\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# find differences in columns\n",
    "\n",
    "print(set(tweets_2020)-(set(tweets_2021)))\n",
    "print(set(tweets_2021)-(set(tweets_2020)))\n",
    "print(set(tweets_2021).symmetric_difference(set(tweets_2022)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make column names match between dataframes\n",
    "\n",
    "tweets_2020 = tweets_2020.rename(columns = {\"day\":\"day_of_week\", \"hour\":\"hour_of_day\"})\n",
    "\n",
    "tweets_2021 = tweets_2021.rename(columns = {\"retweets_count\":\"nretweets\", \"replies_count\":\"nreplies\", \"likes_count\":\"nlikes\"})\n",
    "tweets_2022 = tweets_2022.rename(columns = {\"retweets_count\":\"nretweets\", \"replies_count\":\"nreplies\", \"likes_count\":\"nlikes\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make one column with date and time\n",
    "tweets_2021[\"date\"] = tweets_2021[\"date\"] + \" \" + tweets_2021[\"time\"]\n",
    "tweets_2021 = tweets_2021.drop([\"time\"], 1)\n",
    "\n",
    "tweets_2022[\"date\"] = tweets_2022[\"date\"] + \" \" + tweets_2022[\"time\"]\n",
    "tweets_2022 = tweets_2022.drop([\"time\"], 1)\n",
    "\n",
    "# make the date columns as date in pandas\n",
    "for i in [tweets_2020, tweets_2021, tweets_2022]:\n",
    "    i[\"date\"] = pd.to_datetime(i[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns that were in one data frame but not the others\n",
    "\n",
    "tweets_2021[\"day_of_week\"] = tweets_2021[\"date\"].dt.dayofweek + 1\n",
    "tweets_2022[\"day_of_week\"] = tweets_2022[\"date\"].dt.dayofweek + 1\n",
    "\n",
    "tweets_2021[\"hour_of_day\"] = tweets_2021[\"date\"].dt.hour\n",
    "tweets_2022[\"hour_of_day\"] = tweets_2022[\"date\"].dt.hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id_str', 'search'}\n",
      "{'mentions'}\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# check again differences in columns\n",
    "\n",
    "print(set(tweets_2020)-(set(tweets_2021)))\n",
    "print(set(tweets_2021)-(set(tweets_2020)))\n",
    "print(set(tweets_2021).symmetric_difference(set(tweets_2022)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11717, 38)\n",
      "(3115, 37)\n",
      "(514, 37)\n"
     ]
    }
   ],
   "source": [
    "print(tweets_2020.shape)\n",
    "print(tweets_2021.shape)\n",
    "print(tweets_2022.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15346, 39)\n"
     ]
    }
   ],
   "source": [
    "# make one df out of all 3 datasets\n",
    "tweets = tweets_2020.append(tweets_2021, ignore_index= True)\n",
    "tweets = tweets.append(tweets_2022, ignore_index= True)\n",
    "print(tweets.shape)\n",
    "tweets = tweets.sort_values(by=['date'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all empty columns\n",
    "\n",
    "#tweets.info()\n",
    "tweets = tweets.dropna(1, how=\"all\")\n",
    "#tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tweets df to csv\n",
    "tweets.to_csv('data/needed/cleaned/Tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data sets\n",
    "\n",
    "stock_2018 = pd.read_csv('data/needed/raw/TSLA_2010_2018.csv')\n",
    "stock_2022 = pd.read_csv('data/needed/raw/TSLA_2017_2022.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since \"Adj Close\" os always the same as \"Close\" we drop it\n",
    "stock_2018 = stock_2018.drop([\"Adj Close\"], 1)\n",
    "\n",
    "# rename \"Close/Last\" to \"Close\" to merge df's\n",
    "stock_2022 = stock_2022.rename(columns = {\"Close/Last\":\"Close\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the date columns as date in pandas\n",
    "stock_2022[\"Date\"] = pd.to_datetime(stock_2022[\"Date\"], format=\"%m/%d/%Y\")\n",
    "stock_2018[\"Date\"] = pd.to_datetime(stock_2018[\"Date\"], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2056, 6)\n",
      "(1260, 6)\n"
     ]
    }
   ],
   "source": [
    "print(stock_2018.shape)\n",
    "print(stock_2022.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3316, 6)\n",
      "(2957, 6)\n"
     ]
    }
   ],
   "source": [
    "# put the 2 df's together and remove all duplicates\n",
    "stock = stock_2018.append(stock_2022, ignore_index=True)\n",
    "print(stock.shape)\n",
    "\n",
    "stock = stock.drop_duplicates(subset=[\"Date\"])\n",
    "print(stock.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save stock df to csv\n",
    "stock = stock.sort_values(by=['Date'], ascending=False)\n",
    "stock.to_csv('data/needed/cleaned/Stock.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f3eb201a0ac6110943912f566930be6c3d5ab858ab2721a656c3fdb1d45e052"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
